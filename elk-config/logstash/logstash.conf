# Logstash configuration file to parse logs from services and send them to Elasticsearch

input {
    # File input for NGINX logs
    file {
        path => "/var/log/nginx/*.log"
        start_position => "beginning"
        sincedb_path => "/dev/null"
    }
    # File input for Elysia logs
    file {
        path => "/var/log/elysia/*.log"
        start_position => "beginning"
        sincedb_path => "/dev/null"
    }
}

filter {
    # Conditional filter for NGINX logs
    if [path] =~ "nginx" {
        mutate {
            add_field => {
                "data_source" => "nginx"
            }
        }
        # json {
        #     source => "message"
        # }
        # date {
        #     match => ["timestamp", "ISO8601"]
        # }
        if [program] == "nginx_access" {
            grok {
                patterns_dir => "/usr/share/logstash/pipeline/patterns"
                match => { "message" => "%{NGINX_ACCESS}" }
                remove_tag => ["nginx_access", "_grokparsefailure"]
                add_field => {
                    "type" => "nginx_access"
                }
                remove_field => ["program"]
            }

            date {
                match => ["time_local", "dd/MMM/YYYY:HH:mm:ss Z"]
                target => "@timestamp"
                remove_field => "time_local"
            }

            useragent {
                source => "user_agent"
                target => "useragent"
                remove_field => "user_agent"
            }
        }

        if [program] == "nginx_error" {
            grok {
                patterns_dir => "/usr/share/logstash/pipeline/patterns"
                match => { "message" => "%{NGINX_ERROR}" }
                remove_tag => ["nginx_error", "_grokparsefailure"]
                add_field => {
                    "type" => "nginx_error"
                }
                remove_field => ["program"]
            }

            date {
                match => ["time_local", "YYYY/MM/dd HH:mm:ss"]
                target => "@timestamp"
                remove_field => "time_local"
            }
        }
    }
    
    # Conditional filter for Elysia logs
    else if [path] =~ "elysia" {
        mutate {
            add_field => {
                "data_source" => "elysia"
            }
        }
        json {
            source => "message"
        }
        date {
            match => ["timestamp", "ISO8601"]
        }
    }

    # Conditional filter for Websraper logs
    else if [path] =~ "ws" {
        mutate {
            add_field => {
                "data_source" => "ws"
            }
        }
        json {
            source => "message"
        }
        date {
            match => ["timestamp", "ISO8601"]
        }
    }
}

output {
    # Output to Elasticsearch
    elasticsearch {
        user => "${ELASTIC_USERNAME}"
        password => "${ELASTIC_PASSWORD}"
        hosts => ["elasticsearch:9200"]
        index => "logs-%{+YYYY.MM.dd}"
        # index => "%{data_source}-logs-%{+YYYY.MM.dd}"
    }

    # Output to stdout for debugging purposes
    stdout { codec => rubydebug }
}
